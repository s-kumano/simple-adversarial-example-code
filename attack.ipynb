{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as TF\n",
    "import torchattacks\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "\n",
    "from utils.utils import ModelWithNormalization, freeze\n",
    "\n",
    "# setup model\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "model = resnet18(weights=weights)\n",
    "model = model.eval()\n",
    "freeze(model)\n",
    "model = ModelWithNormalization(model, [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# ImageNet labels\n",
    "label_path = os.path.join('data', 'imagenet_labels.txt')\n",
    "with open(label_path, 'r') as f:\n",
    "    labels = f.readlines()\n",
    "\n",
    "# read img\n",
    "p = os.path.join('data', 'plate.JPG')\n",
    "clean_img = cv2.imread(p)\n",
    "clean_img = cv2.cvtColor(clean_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# preprocess img for torch model\n",
    "clean_img = clean_img.transpose(2, 0, 1)\n",
    "clean_img = torch.from_numpy(clean_img)\n",
    "img_size = 400\n",
    "clean_img = VF.resize(clean_img, [img_size, img_size], antialias=True)\n",
    "clean_img = clean_img / 255\n",
    "clean_img = clean_img.view(1, 3, img_size, img_size)\n",
    "\n",
    "# prediction for clean img\n",
    "clean_probs = TF.softmax(model(clean_img), dim=1)\n",
    "sorted_clean_probs, sorted_clean_indices = clean_probs[0].sort(descending=True)\n",
    "sorted_clean_probs *= 100\n",
    "predicted_index_for_clean_img = sorted_clean_indices[0]\n",
    "predicted_label_for_clean_img = labels[predicted_index_for_clean_img]\n",
    "\n",
    "# attack\n",
    "atk = torchattacks.PGD(model, 8/255, steps=100)\n",
    "adv_img = atk(clean_img, torch.tensor([predicted_index_for_clean_img]))\n",
    "\n",
    "# prediction for adv img\n",
    "adv_probs = TF.softmax(model(adv_img), dim=1)\n",
    "sorted_adv_probs, sorted_adv_indices = adv_probs[0].sort(descending=True)\n",
    "sorted_adv_probs *= 100\n",
    "predicted_index_for_adv_img = sorted_adv_indices[0]\n",
    "predicted_label_for_adv_img = labels[predicted_index_for_adv_img]\n",
    "\n",
    "# show imgs\n",
    "plt.axis('off')\n",
    "plt.imshow(clean_img[0].permute(1, 2, 0))\n",
    "plt.show()\n",
    "plt.axis('off')\n",
    "plt.imshow(adv_img[0].permute(1, 2, 0))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
