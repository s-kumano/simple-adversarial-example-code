{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import base64\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "import cv2\n",
    "import IPython.display\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torchvision.transforms.functional as VF\n",
    "\n",
    "from utils.mlp import MLP\n",
    "from utils.utils import ModelWithNormalization, freeze\n",
    "\n",
    "# setting\n",
    "builtin_camera = True\n",
    "\n",
    "# capture setup\n",
    "capture = cv2.VideoCapture(0)\n",
    "assert capture.isOpened(), 'Could not open video device'\n",
    "\n",
    "# frame sampling setting\n",
    "frame_count = 0\n",
    "update_rate = 10\n",
    "\n",
    "# crop setting\n",
    "height = 720 if builtin_camera else 1080\n",
    "width = 1280 if builtin_camera else 1920\n",
    "width_start = (width - height) // 2\n",
    "width_end = width_start + height\n",
    "\n",
    "# buffer\n",
    "buf_movie = BytesIO()\n",
    "\n",
    "# define model\n",
    "models = {}\n",
    "widths = [125, 1000]\n",
    "for width in widths:\n",
    "    model = MLP(784, width, 10, 5, True)\n",
    "    model = ModelWithNormalization(model, [0.1307], [0.3081])\n",
    "    model = model.eval()\n",
    "    freeze(model)\n",
    "    # load weight\n",
    "    weight_path = os.path.join('..', 'weights', f'width={width}.ckpt')\n",
    "    weight = torch.load(weight_path)\n",
    "    model.load_state_dict(weight)\n",
    "    models[width] = model\n",
    "\n",
    "# IPython setup\n",
    "handle = IPython.display.DisplayHandle()\n",
    "handle.display(IPython.display.HTML(''))\n",
    "\n",
    "try:\n",
    "\n",
    "    while(True):\n",
    "        success, frame = capture.read() # (bool, numpy.ndarray)\n",
    "\n",
    "        #print(frame.shape) # external: (1080, 1920, 3), builtin: (720, 1280, 3)\n",
    "        #break\n",
    "\n",
    "        if success:\n",
    "\n",
    "            if frame_count % update_rate == 0: # frame sampling\n",
    "                frame_count = 0\n",
    "\n",
    "                # preprocess frame\n",
    "                frame = frame[:, width_start:width_end] # crop to square\n",
    "                frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5) # compress to 50%\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # prediction\n",
    "                model_input = frame.transpose(2, 0, 1)\n",
    "                model_input = torch.from_numpy(model_input)\n",
    "                img_size = 28\n",
    "                model_input = VF.resize(model_input, [img_size, img_size], antialias=None)\n",
    "                model_input = model_input / 255\n",
    "                model_input = model_input.view(1, 3, img_size, img_size)\n",
    "                model_input = model_input.mean(1)\n",
    "\n",
    "                predicted_numbers = {}\n",
    "                for width in widths:\n",
    "                    predicted_numbers[width] = model(model_input).max(1).indices.item()\n",
    "\n",
    "                # movie display\n",
    "                PIL.Image.fromarray(frame).save(buf_movie, 'png')\n",
    "                encoded_movie = base64.b64encode(buf_movie.getvalue()).decode('utf-8')\n",
    "\n",
    "                # IPython\n",
    "                html = \\\n",
    "                f\"\"\"\n",
    "                <div style=\"display: flex; justify-content: center; align-items: start; width: 90%;\">\n",
    "                  <div style=\"flex: 1; display: flex; justify-content: center; align-items: center;\">\n",
    "                    <img src=\"data:image/png;base64,{encoded_movie}\" style=\"width: 90%; height: 90%; object-fit: contain;\">\n",
    "                  </div>\n",
    "                  <div style=\"flex: 1; display: flex; flex-direction: column; justify-content: space-between;\">\n",
    "                    <div style=\"display: table;\">\n",
    "                      <div style=\"display: table-row; margin-bottom: 20px;\">\n",
    "                        <div style=\"display: table-cell; text-align: left; width: 160pt;\">\n",
    "                          <font size=\"7\">幅 125:</font>\n",
    "                        </div>\n",
    "                        <div style=\"display: table-cell; text-align: left;\">\n",
    "                          <font size=\"7\">予測 {predicted_numbers[125]}</font>\n",
    "                        </div>\n",
    "                      </div>\n",
    "                      <div style=\"display: table-row;\">\n",
    "                        <div style=\"display: table-cell; text-align: left; width: 160pt;\">\n",
    "                          <font size=\"7\">幅 1000:</font>\n",
    "                        </div>\n",
    "                        <div style=\"display: table-cell; text-align: left;\">\n",
    "                          <font size=\"7\">予測 {predicted_numbers[1000]}</font>\n",
    "                        </div>\n",
    "                      </div>\n",
    "                    </div>\n",
    "                  </div>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                handle.update(IPython.display.HTML(html))\n",
    "\n",
    "                # clear BytesIO object\n",
    "                buf_movie.seek(0)\n",
    "                buf_movie.truncate()\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    capture.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
