{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "import cv2\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as TF\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "\n",
    "# setting\n",
    "builtin_camera = True\n",
    "\n",
    "# mpl setting\n",
    "sns.set_theme()\n",
    "sns.set_context('notebook', 2)\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "# capture setup\n",
    "capture = cv2.VideoCapture(0)\n",
    "assert capture.isOpened(), 'Could not open video device'\n",
    "\n",
    "# ImageNet labels\n",
    "label_path = os.path.join('..', 'data', 'imagenet_labels.txt')\n",
    "with open(label_path, 'r') as f:\n",
    "    labels = f.readlines()\n",
    "\n",
    "# frame sampling setting\n",
    "frame_count = 0\n",
    "update_rate = 10\n",
    "\n",
    "# crop setting\n",
    "height = 720 if builtin_camera else 1080\n",
    "width = 1280 if builtin_camera else 1920\n",
    "width_start = (width - height) // 2\n",
    "width_end = width_start + height\n",
    "\n",
    "# buffer\n",
    "buf_movie = BytesIO()\n",
    "buf_graph = BytesIO()\n",
    "\n",
    "# model setup\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "model = resnet18(weights=weights)\n",
    "model = model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# IPython setup\n",
    "handle = IPython.display.DisplayHandle()\n",
    "handle.display(IPython.display.HTML(''))\n",
    "\n",
    "try:\n",
    "\n",
    "    while(True):\n",
    "        success, frame = capture.read() # (bool, numpy.ndarray)\n",
    "\n",
    "        #print(frame.shape) # external: (1080, 1920, 3), builtin: (720, 1280, 3)\n",
    "        #break\n",
    "\n",
    "        if success:\n",
    "\n",
    "            if frame_count % update_rate == 0: # frame sampling\n",
    "                frame_count = 0\n",
    "\n",
    "                # preprocess frame\n",
    "                frame = frame[:, width_start:width_end] # crop to square\n",
    "                frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5) # compress to 50%\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # prediction\n",
    "                model_input = frame.transpose(2, 0, 1)\n",
    "                model_input = torch.from_numpy(model_input)\n",
    "                model_input = VF.resize(model_input, [224, 224], antialias=None)\n",
    "                model_input = model_input / 255\n",
    "                model_input = model_input.view(1, 3, 224, 224)\n",
    "                model_input = VF.normalize(model_input, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                probs = TF.softmax(model(model_input), dim=1)\n",
    "                sorted_probs, sorted_indices = probs[0].sort(descending=True)\n",
    "                sorted_probs *= 100\n",
    "\n",
    "                # movie display\n",
    "                PIL.Image.fromarray(frame).save(buf_movie, 'png')\n",
    "                encoded_movie = base64.b64encode(buf_movie.getvalue()).decode('utf-8')\n",
    "\n",
    "                # graph\n",
    "                display_items = 3\n",
    "                x = [i for i in range(display_items)]\n",
    "                top_probs = sorted_probs[:display_items].flip(0)\n",
    "                top_labels = [labels[i] for i in sorted_indices[:display_items]]\n",
    "                top_labels.reverse() # for plot\n",
    "                bar = plt.barh(x, top_probs, tick_label=top_labels)\n",
    "\n",
    "                # mpl setting\n",
    "                plt.xlabel('Probability (%)')\n",
    "                plt.xlim(0, 100)\n",
    "\n",
    "                # graph display\n",
    "                plt.subplots_adjust(left=0.3, right=0.97, bottom=0.15, top=0.995)\n",
    "                plt.savefig(buf_graph, format='png')\n",
    "                plt.close()\n",
    "                encoded_graph = base64.b64encode(buf_graph.getvalue()).decode('utf-8')\n",
    "\n",
    "                # IPython\n",
    "                html = \\\n",
    "                f\"\"\"\n",
    "                <div style=\"display: flex; justify-content: center; align-items: stretch;\">\n",
    "                  <div style=\"flex: 1; display: flex; justify-content: center;\">\n",
    "                    <img src=\"data:image/png;base64,{encoded_movie}\" style=\"max-width: 120%; height: 100%; object-fit: contain;\">\n",
    "                  </div>\n",
    "                  <div style=\"flex: 1; display: flex; justify-content: center;\">\n",
    "                    <img src=\"data:image/png;base64,{encoded_graph}\" style=\"max-width: 120%; height: 100%; object-fit: contain;\">\n",
    "                  </div>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                handle.update(IPython.display.HTML(html))\n",
    "\n",
    "                # clear BytesIO object\n",
    "                buf_movie.seek(0)\n",
    "                buf_graph.seek(0)\n",
    "                buf_movie.truncate()\n",
    "                buf_graph.truncate()\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    capture.release()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
